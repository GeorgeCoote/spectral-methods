## Mathematical pre-requisites

A first course in functional analysis, including some spectral theory is useful. My choice of texts would be Conway's A Course in Functional Analysis and Hislop/Segal's Introduction to Spectral Theory. An understanding of finite-dimensional linear algebra and topological vocabulary will be essential. You should be familiar with the following terms/ideas. 

* The distance of a point to a closed set
* Continuous function
* Linear operator
* Hilbert Space
* Closed operator
* Densely-defined unbounded operator
* Self-adjoint operator (in the unbounded setting)
* Orthonormal basis, and what it means to represent a linear operator as an infinite matrix in a given orthonormal basis
* Eigenvalue, eigenvector, spectrum, spectral point, resolvent set
* Positive semi-definite

Some less immediate definitions:
* **Matrix element**: Let `H` be a Hilbert space with inner product < , >. Let `A` be an operator from a Hilbert space `H` to itself. Let `E = (e_i)` be an orthonormal basis for `H`. We refer to `<A e_j, e_i>` as the matrix element at the `(i, j)` position. When we express `A` as an infinite matrix in the basis `E`, `<A e_j, e_i>` is the element on the `i`th row, `j`th column. This is because `A e_j` gives the `j`th column, and letting it act on `e_i` extracts the `i`th entry of this vector (corresponding to the `i`th row). 

## High-level design decisions

* **Precision is prioritised over speed**: where possible, `Fraction` objects are used as opposed to `float`s so as to enable exact arithmetic. Complex numbers generated by class functions are typically given as tuples of `Fraction` objects, since they are known exactly. Complex numbers originating from user input are not expected to be exactly specified or exactly known and so are allowed to have `float`-type real and imaginary parts.
* **Slower reference implementations (marked by _slow) are included pedagogical purposes**: the `_slow` versions of functions represent the most straightforward, but sub-optimal, approach and serve the foundation of more optimized versions. Sometimes they represent direct translations of the pseudocode found in Colbrook and Hansen (2022). Since the pseudocode was written to most clearly demonstrate the algorithms, optimization for more practical implementation is to be expected. For example, `CompInvg_slow` represents a linear search (achieving `O(n)` time complexity), whereas `CompInvg` uses a binary search (achieving an improved `O(log n)` time complexity). The possibility of binary searches as opposed to linear searches was noted in the paper.
* **Matrices are described with `Callable`s rather than individual matrix elements**: In the Markov model of computation, matrices `(a_ij)` are described by Turing machines computing the function `(i, j) -> a_ij`. Since a `Callable` can in principle be simulated on a Turing machine, and therefore faithfully captures this theoretical setup. The `Callable` is used to generate an `np.array` where needed for numerical computations, via the `_generate_matrix` helper function.

## Example of specifying a matrix by a `Callable`

A few examples of how one may specify a matrix via a `Callable` are given below.

### Alternating squares matrix 

```python
def alternating_squares(i : int, j : int) -> int:
  '''Generates the matrix consisting of 0, -1, 4, -9, ... on its diagonal. That is:
  [0   0    0   0  ..]
  [0   -1   0   0  ..]
  [0   0    4   0  ..]
  [0   0    0   -9 ..]
  ...
  '''
  if i == j:
    sign = (2*((i + 1)%2) - 1) # (-1)^i
    return sign*i*i # (-1)^i * i^2
  else:
    return 0
```

In this case, if `A = alternating_squares`, we have an exact formula for the `(i, j)`th matrix element of `A`. The only data that is stored is the code for the function `alternating_squares`, until an evaluation is needed by a numerical computation. 
